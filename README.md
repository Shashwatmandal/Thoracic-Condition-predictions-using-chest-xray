# ğŸ©» Chest X-Ray Pathology Classification â€” Grand X-Ray Slam (Division B)

This repository contains my solutions for the **[Grand X-Ray Slam (Division B)](https://www.kaggle.com/competitions/grand-xray-slam-division-b)** Kaggle competition.  
The objective is to develop a deep learning model that can **automatically classify chest X-rays into multiple pathology classes** with high diagnostic accuracy.

---

## ğŸš€ Project Overview

- Processed **40K+ chest X-ray images across 14 pathology classes** to build a high-quality dataset.  
- Applied **CLAHE-based contrast enhancement**, removed corrupted images, and performed **advanced data augmentation** (rotations, flips, random crops) for better generalization.  
- Trained a **DenseNet-121 multi-label classifier** with **5-fold cross-validation**, achieving an average **macro-AUC of 0.91 Â± 0.02** using `BCEWithLogitsLoss` and ROC-AUC metrics.  
- Experimented with a **Qwen Vision Transformer pipeline** for multimodal (vision-language) learning and improved robustness.  

---

## ğŸ§  Models Implemented

| Model | Description | Framework |
|--------|--------------|------------|
| **DenseNet-121** | CNN-based baseline pretrained on ImageNet and fine-tuned for 14-class multi-label classification. | PyTorch |
| **Qwen Vision Pipeline** | Multimodal transformer using image + language embeddings for X-ray reasoning. | Hugging Face Transformers |

---

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ densenet-1.ipynb          # DenseNet-121 training & evaluation notebook
â”œâ”€â”€ Qwen Pipeline.ipynb       # Qwen Vision multimodal pipeline
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ requirements.txt          # Python dependencies (optional)
```

---

## ğŸ‹ï¸ Model Training

### DenseNet-121 Training
```python
# Inside densenet-1.ipynb
# - Load dataset and preprocess with CLAHE
# - Apply data augmentation
# - Train with BCEWithLogitsLoss and 5-fold CV
# - Evaluate macro-AUC and save best weights
```

### Qwen Vision Pipeline
```python
# Inside Qwen Pipeline.ipynb
# - Use Qwen-Vision model for multimodal X-ray understanding
# - Optionally fine-tune on annotated text prompts
# - Evaluate zero-shot or fine-tuned performance
```

---

## ğŸ“Š Results Summary

| Model | Notes |
|--------|-------|
| DenseNet-121 | Strong CNN baseline |
| Qwen Vision Pipeline | Multimodal experimentation |

---

## ğŸ“ˆ Visualizations

- **Training curves** for loss and ROC-AUC  
- **Grad-CAM heatmaps** for explainability  
- **Confusion matrices** to identify misclassifications  

(Plots are available inside the notebooks.)

---

## ğŸ§© Future Enhancements

- Incorporate **ensemble averaging** between DenseNet and Qwen models  
- Use **Swin Transformer** and **EfficientNet-V2** for stronger baselines  
- Integrate **explainability metrics** and uncertainty estimation  

---

## ğŸ Acknowledgments

- [Kaggle â€” Grand X-Ray Slam Division B](https://www.kaggle.com/competitions/grand-xray-slam-division-b)  
- [PyTorch](https://pytorch.org/)  
- [Hugging Face Transformers](https://huggingface.co/transformers/)  
- [Qwen-VL](https://huggingface.co/Qwen)

---

## ğŸ“œ License

This repository is licensed under the **MIT License**.  
Feel free to use, modify, and share with attribution.

---
